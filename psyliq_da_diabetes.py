# -*- coding: utf-8 -*-
"""Psyliq_DA_Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ETcsZ3T9eqKvaEnKiVmIWfJcLVZsyyO4
"""

# Step 1: Import the necessary libraries
from google.colab import files
import pandas as pd

# Step 2: Use the upload function to upload the file
uploaded = files.upload()

df = pd.read_excel('Diabetes_prediction.xlsx')
df

# Convert D.O.B to datetime with error handling
df['D.O.B'] = pd.to_datetime(df['D.O.B'], errors='coerce')

#Q1
# Calculate age based on date of birth, handling NaT values
df['Age'] = df['D.O.B'].apply(lambda dob: (datetime.now() - dob).days // 365 if pd.notnull(dob) else None)

# Retrieve Patient_id and ages
patient_ages = df[['Patient_id', 'Age']]
print(patient_ages)

#Q2
female_over_30 = df[(df['gender'] == 'Female') & (df['Age'] > 30)]
print(female_over_30)

#Q3
average_bmi = df['bmi'].mean()
print(f'Average BMI: {average_bmi}')

#Q4
sorted_by_glucose = df.sort_values(by='blood_glucose_level', ascending=False)
print(sorted_by_glucose)

#Q5
hypertension_and_diabetes = df[(df['hypertension'] == 1) & (df['diabetes'] == 'Yes')]
print(hypertension_and_diabetes)

#Q6
num_heart_disease = df[df['heart_disease'] == 1].shape[0]
print(f'Number of patients with heart disease: {num_heart_disease}')

#Q7
smoking_counts = df['smoking_history'].value_counts()
print(smoking_counts)

#Q8
patients_high_bmi = df[df['bmi'] > average_bmi]['Patient_id']
print(patients_high_bmi)

#Q9
highest_hba1c_patient = df.loc[df['HbA1c_level'].idxmax()]
lowest_hba1c_patient = df.loc[df['HbA1c_level'].idxmin()]
print(f'Highest HbA1c level patient:\n{highest_hba1c_patient}')
print(f'Lowest HbA1c level patient:\n{lowest_hba1c_patient}')

#Q10
# Already calculated in Step 1
print(df[['Patient_id', 'Age']])

#Q11
df['glucose_rank'] = df.groupby('gender')['blood_glucose_level'].rank(ascending=False)
print(df)

#Q12
df.loc[df['Age'] > 40, 'smoking_history'] = 'Ex-smoker'
print(df)

#Q13
new_patient = {
    'EmployeeName': 'Robert Brown',
    'Patient_id': 4,
    'gender': 'Male',
    'D.O.B': '1970-03-22 00:00:00',
    'hypertension': 1,
    'heart_disease': 0,
    'smoking_history': 'never',
    'bmi': 28.0,
    'HbA1c_level': 6.5,
    'blood_glucose_level': 120,
    'diabetes': 'Yes'
}

# Convert to DataFrame and append
new_patient_df = pd.DataFrame([new_patient])
new_patient_df['D.O.B'] = pd.to_datetime(new_patient_df['D.O.B'], errors='coerce')

#Q14
df = df[df['heart_disease'] != 1]
print(df)

#Q15
hypertension_not_diabetes = df[(df['hypertension'] == 1) & (df['diabetes'] != 'Yes')]
print(hypertension_not_diabetes)

#Q16
assert df['Patient_id'].is_unique, "Patient_id values are not unique!"

#Q17
patient_view = df[['Patient_id', 'Age', 'bmi']]
print(patient_view)

"""### 18. Improvements in the Database Schema

To reduce data redundancy and improve data integrity, consider the following improvements:

#### Normalization
Normalization involves organizing the database to reduce redundancy and improve data integrity. This typically involves dividing large tables into smaller, related tables.

1. **First Normal Form (1NF)**:
    - Ensure that each column contains only atomic (indivisible) values, and each entry in a column is of the same data type.

2. **Second Normal Form (2NF)**:
    - Ensure that the database is in 1NF and all non-key attributes are fully functional dependent on the primary key.

3. **Third Normal Form (3NF)**:
    - Ensure that the database is in 2NF and all attributes are only dependent on the primary key (no transitive dependency).

Example Schema:
```sql
CREATE TABLE Patients (
    Patient_id INT PRIMARY KEY,
    EmployeeName VARCHAR(255),
    Gender VARCHAR(50),
    DOB DATE,
    Hypertension BOOLEAN,
    HeartDisease BOOLEAN,
    SmokingHistory VARCHAR(50),
    BMI DECIMAL(5, 2),
    HbA1cLevel DECIMAL(4, 2),
    BloodGlucoseLevel DECIMAL(5, 2),
    Diabetes BOOLEAN
);

CREATE TABLE MedicalConditions (
    Condition_id INT PRIMARY KEY,
    ConditionName VARCHAR(255)
);

CREATE TABLE PatientConditions (
    Patient_id INT,
    Condition_id INT,
    FOREIGN KEY (Patient_id) REFERENCES Patients(Patient_id),
    FOREIGN KEY (Condition_id) REFERENCES MedicalConditions(Condition_id)
);
```

#### Adding Constraints
Use constraints to enforce data integrity:

1. **Primary Key**: Ensure each table has a primary key.
2. **Foreign Key**: Use foreign keys to maintain referential integrity between related tables.
3. **Unique Constraint**: Ensure certain fields are unique where necessary (e.g., Patient_id).
4. **Not Null Constraint**: Ensure critical fields are not null.
5. **Check Constraint**: Use check constraints to enforce domain integrity.

Example:
```sql
ALTER TABLE Patients
ADD CONSTRAINT chk_gender CHECK (gender IN ('Male', 'Female'));

ALTER TABLE Patients
ADD CONSTRAINT chk_smoking_history CHECK (smoking_history IN ('never', 'former', 'current'));
```

### 19. Optimizing SQL Query Performance

To optimize the performance of SQL queries on this dataset, consider the following strategies:

#### Indexing
Indexes can significantly improve the speed of data retrieval. Create indexes on columns that are frequently used in WHERE clauses, JOIN conditions, and ORDER BY clauses.

Example:
```sql
CREATE INDEX idx_patients_gender ON Patients(Gender);
CREATE INDEX idx_patients_dob ON Patients(DOB);
CREATE INDEX idx_patients_blood_glucose_level ON Patients(BloodGlucoseLevel);
```

#### Query Optimization
Analyze and optimize your queries to ensure they are as efficient as possible.

1. **Use EXPLAIN**: Use the EXPLAIN statement to understand how the database executes a query.
2. **Avoid SELECT ***: Select only the columns you need.
3. **Use Joins Appropriately**: Ensure joins are necessary and use indexes to optimize them.
4. **Limit Results**: Use LIMIT to restrict the number of rows returned by a query.

Example:
```sql
EXPLAIN SELECT Patient_id, Gender, Age FROM Patients WHERE Age > 30;
```

#### Partitioning
For very large tables, consider partitioning to improve performance.

Example:
```sql
CREATE TABLE Patients (
    Patient_id INT,
    ...
) PARTITION BY RANGE (YEAR(DOB));
```

#### Caching
Use caching to store frequently accessed data in memory, reducing the need for repeated database queries.

Example:
```sql
-- Example using a caching layer like Redis
SET redis_cache = GET 'patients_age_above_30';
IF redis_cache IS NULL THEN
    SELECT * FROM Patients WHERE Age > 30;
    SET redis_cache = result;
END IF;
```

#### Database Configuration
Ensure your database server is configured for optimal performance:
1. **Adjust Memory Allocation**: Ensure the database server has sufficient memory allocated.
2. **Connection Pooling**: Use connection pooling to manage database connections efficiently.
3. **Regular Maintenance**: Perform regular maintenance tasks like vacuuming, analyzing, and reindexing.

By following these steps, you can improve the performance and integrity of your database, making it more efficient and reliable for handling queries and operations.
"""